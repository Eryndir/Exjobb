{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "\n",
    "from json import loads\n",
    "\n",
    "# from time import sleep\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import kblab \n",
    "import math\n",
    "from pandas.core.frame import DataFrame\n",
    "from tqdm import tqdm\n",
    "from urllib3.util import Retry\n",
    "from urllib3 import PoolManager, make_headers\n",
    "from kblab import Archive\n",
    "import regex as re\n",
    "from itertools import product\n",
    "kblab.VERIFY_CA=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = range(1920, 1930)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_content: DataFrame = pd.read_feather(f\"data/df_content_new_{years[0]}s.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/birdNewsData/data/df_content_new_1920s.feather'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_content: DataFrame \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_feather\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/data/birdNewsData/data/df_content_new_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43myears\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43ms.feather\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/Exjobb-main/venv/lib/python3.12/site-packages/pandas/io/feather_format.py:120\u001b[0m, in \u001b[0;36mread_feather\u001b[0;34m(path, columns, use_threads, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension_types\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[1;32m    118\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    122\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_backend \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_pyarrow_string_dtype():\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m feather\u001b[38;5;241m.\u001b[39mread_feather(\n\u001b[1;32m    125\u001b[0m             handles\u001b[38;5;241m.\u001b[39mhandle, columns\u001b[38;5;241m=\u001b[39mcolumns, use_threads\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m(use_threads)\n\u001b[1;32m    126\u001b[0m         )\n",
      "File \u001b[0;32m~/code/Exjobb-main/venv/lib/python3.12/site-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/birdNewsData/data/df_content_new_1920s.feather'"
     ]
    }
   ],
   "source": [
    "#df_content: DataFrame = pd.read_feather(f\"/data/birdNewsData/data/df_content_new_{years[0]}s.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_content\n",
    "df_numpy = np.array(df_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = r\"\\p{L}+\"\n",
    "def tokenize(text):\n",
    "  return re.finditer(regex, text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_idx(words):\n",
    "  wordCount = 0\n",
    "  wordPos = {}\n",
    "  for token in words:\n",
    "    wordCount+=1\n",
    "    word = token.group()\n",
    "    pos = token.span()[0]\n",
    "    if word in wordPos.keys():\n",
    "      wordPos[word].append(pos)\n",
    "    else:\n",
    "      wordPos[word] = [pos]\n",
    "  return wordPos, wordCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['men', 'hallå', 'där'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenize(\"Men hallå där!\")\n",
    "idx, wordCount = text_to_idx(tokens)\n",
    "print(wordCount)\n",
    "idx.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDeclension(word):\n",
    "  if word[-2:] == \"ås\":\n",
    "    root = word[:-2]\n",
    "    return [word, f\"{word}en\", f\"{root}äss\", f\"{root}ässen\"]\n",
    "  if word[-2:] == \"tt\" or word[-2:] == \"st\":\n",
    "    root = word[:-1]\n",
    "    return [word, f\"{word}en\", f\"{word}ar\", f\"{word}arna\"]\n",
    "  if word[-2:] == \"rt\":\n",
    "    root = word[:-1]\n",
    "    return [word, f\"{word}en\", f\"{word}ar\", f\"{word}arna\"]\n",
    "  if word[-1:] == \"t\":\n",
    "    root = word[:-1]\n",
    "    return [word, f\"{word}en\", f\"{word}er\", f\"{word}erna\"]\n",
    "  if word[-3:] == \"gam\":\n",
    "    return [word, f\"{word}en\", f\"{word}ar\", f\"{word}arna\"]\n",
    "  if word[-1:] == \"m\":\n",
    "    return [word, f\"{word}men\", f\"{word}mar\", f\"{word}marna\"]\n",
    "  if word[-2:] == \"ss\":\n",
    "    return [word, f\"{word}en\", f\"{word}er\", f\"{word}erna\"]\n",
    "  if word[-1:] == \"a\":\n",
    "    root = word[:-1]\n",
    "    return [word, f\"{root}an\", f\"{root}or\", f\"{root}orna\"]\n",
    "  if word[-2:] == \"yr\":\n",
    "    root = word[:-2]\n",
    "    return [word, f\"{word}en\", f\"{root}rar\", f\"{root}rarna\"]\n",
    "  if word[-3:] == \"ger\":\n",
    "    root = word[:-2]\n",
    "    return [word, f\"{root}ern\", f\"{root}rar\", f\"{root}rarna\"]\n",
    "  if word[-1:] == \"r\" and (not word[-2:] == \"är\"):\n",
    "    root = word[:-1]\n",
    "    return [word, f\"{word}et\", f\"{word}\", f\"{word}en\"]\n",
    "  if word[-1:] == \"d\":\n",
    "    root = word[:-3]\n",
    "    return [word, f\"{word}et\", f\"{root}änder\", f\"{root}änderna\"]\n",
    "  if word[-3:] == \"are\" and (not word[-5:] == \"stare\"):\n",
    "    root = word[:-1]\n",
    "    return [word, f\"{root}en\", f\"{root}e\", f\"{root}na\"]\n",
    "  if word[-2:] == \"re\":\n",
    "    root = word[:-1]\n",
    "    return [word, f\"{root}en\", f\"{root}ar\", f\"{root}arna\"]\n",
    "  if word[-1:] == \"e\":\n",
    "    root = word[:-1]\n",
    "    return [word, f\"{root}en\", f\"{root}ar\", f\"{root}arna\"]\n",
    "  if word[-4:] == \"rell\":\n",
    "    root = word[:-2] \n",
    "    return [word, f\"{word}en\", f\"{word}er\", f\"{word}erna\"]\n",
    "  if word[-2:] == \"ll\":\n",
    "    root = word[:-2] \n",
    "    return [word, f\"{word}en\", f\"{word}ar\", f\"{word}arna\"]\n",
    "  if word[-2:] == \"yl\" or word[-3:] == \"nal\":\n",
    "    root = word[:-2] \n",
    "    return [word, f\"{word}en\", f\"{word}er\", f\"{word}erna\"]\n",
    "  if word[-3:] == \"gal\":\n",
    "    root = word[:-2] \n",
    "    return [word, f\"{word}en\", f\"{word}ar\", f\"{word}arna\"]\n",
    "  if word[-1:] == \"l\":\n",
    "    root = word[:-2] \n",
    "    return [word, f\"{root}eln\", f\"{root}lar\", f\"{root}larna\"]\n",
    "  if word[-2:] == \"ag\":\n",
    "    root = word \n",
    "    return [word, f\"{root}et\", f\"{root}\", f\"{root}en\"]\n",
    "  if word[-1:] == \"g\":\n",
    "    root = word \n",
    "    return [word, f\"{root}en\", f\"{root}ar\", f\"{root}arna\"]\n",
    "  if word[-2:] == \"um\":\n",
    "    root = word[:-2] \n",
    "    return [word, f\"{root}en\", f\"{root}nar\", f\"{root}narna\"]\n",
    "  if word[-2:] == \"en\":\n",
    "    root = word[:-2] \n",
    "    return [word, f\"{root}nen\", f\"{root}er\", f\"{root}erna\"]\n",
    "  if word[-2:] == \"an\":\n",
    "    root = word[:-2] \n",
    "    return [word, f\"{word}en\", f\"{word}er\", f\"{word}erna\"]\n",
    "  if word[-2:] == \"ur\" or word[-2:] == \"är\":\n",
    "    root = word[:-2] \n",
    "    return [word, f\"{word}en\", f\"{word}er\", f\"{word}erna\"]\n",
    "  if word[-2:] == \"nd\":\n",
    "    root = word[:-3]\n",
    "    return [word, f\"{word}en\", f\"{root}änder\", f\"{word}änderna\"]\n",
    "  if word[-1:] == \"ö\":\n",
    "    return [word, f\"{word}n\", f\"{word}ar\", f\"{word}arna\"]\n",
    "  if word[-2:] == \"es\":\n",
    "    return [word, f\"{word}en\", f\"{word}ar\", f\"{word}arna\"]\n",
    "  if word[-2:] == \"rk\" or word[-2:] == \"nk\":\n",
    "    return [word, f\"{word}en\", f\"{word}ar\", f\"{word}arna\"]\n",
    "  if word[-2:] == \"ök\" or word[-2:] == \"åk\" or word[-2:] == \"lk\" or word[-2:] == \"ck\":\n",
    "    return [word, f\"{word}en\", f\"{word}ar\", f\"{word}arna\"]\n",
    "  if word[-1:] == \"k\":\n",
    "    return [word, f\"{word}en\", f\"{word}er\", f\"{word}erna\"]\n",
    "  if word[-1:] == \"o\":\n",
    "    return [word, f\"{word}n\", f\"{word}er\", f\"{word}rna\"]\n",
    "  if word[-1:] == \"s\" and (not word[-2:] == \"is\" or not word[-2] == \"es\"):\n",
    "    return [word, f\"{word}et\", f\"{word}\", f\"{word}en\"]\n",
    "  else:\n",
    "    root = word\n",
    "    return [word, f\"{root}en\", f\"{root}ar\", f\"{root}arna\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gås', 'gåsen', 'gäss', 'gässen']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getDeclension(\"gås\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sandbank', 'estuarium', 'sandbotten', 'lerbotten',\n",
       "       'blottade ler- och sandbotten', 'lagun', 'vik', 'sund', 'rev',\n",
       "       'bubbelstruktur', 'driftvall', 'stenvall ', 'grusvall',\n",
       "       'havsklippa', 'strand', 'glasörtstrand', 'salta strandäng', 'ö',\n",
       "       'åsö', 'skär', 'strandäng', 'smala östersjövik', 'dyn', 'fördyn',\n",
       "       'vita dyn', 'grå dyn', 'risdyner', 'sandvidedyn', 'trädklädda dyn',\n",
       "       'dynvåtmark', 'hed', 'rissandhed', 'grässandhedar', 'sjö',\n",
       "       'slättssjö', 'näringsfattiga slättssjöar', 'ävjestrandsjö',\n",
       "       'kransalgssjö', 'näringsrika sjö', 'näringsrik sjö',\n",
       "       'naturligt näringsrika sjö', 'myrsjö', 'vattendrag',\n",
       "       'större vattendrag', 'alpina vattendrag', 'mindre vattendrag',\n",
       "       'fukthed', 'torra hed', 'alpina rished', 'alpina videbuskmark',\n",
       "       'enbuskmark', 'berghäll', 'basiska berghäll', 'sandstäpp', 'mark',\n",
       "       'gräsmark', 'silikatgräsmark', 'alpina silikatgräsmark',\n",
       "       'alpina kalkgräsmark', 'kalkgräsmark', 'stagg-gräsmark', 'alv',\n",
       "       'älv', 'äng', 'fuktäng', 'högörtäng', 'svämäng', 'lågland',\n",
       "       'slåtteräng', 'slåtterängar i lågland', 'höglänta slåtteräng',\n",
       "       'löväng', 'mossa', 'högmossa', 'degenererade högmossa',\n",
       "       'terrängtäckande mossa', 'kärr', 'öppna mossa', 'källa',\n",
       "       'källkärr', 'agkärr', 'kalktuffkälla', 'rikkärr',\n",
       "       'alpina översilningskärr', 'myr', 'apamyr', 'palsmyr',\n",
       "       'silikatrasmark', 'kalkrasmark', 'brant', 'kalkbrant',\n",
       "       'silikatbrant', 'hällmarkstorräng', 'karsthällmark', 'grotta',\n",
       "       'havsgrotta', 'glaciär', 'taiga', 'skog', 'lövskog', 'ädellövskog',\n",
       "       'nordlig ädellövskog', 'landhöjningsskog', 'björkskog',\n",
       "       'fjällbjörkskog', 'granskog', 'näringsrik granskog', 'barrskog',\n",
       "       'åsbarrskog', 'betesmark', 'trädklädd betesmark', 'lövsumpskog',\n",
       "       'bokskog', 'näringsfattig bokskog', 'näringsrik bokskog', 'ekskog',\n",
       "       'näringsrik ekskog', 'ädellövskog i brant', 'näringsfattig ekskog',\n",
       "       'skogsbevuxen myr', 'svämlövskog', 'svämädellövskog'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "birds = pd.read_csv(\"birds2.csv\", header=0)\n",
    "birdsDia = pd.read_csv(\"birdsDialectic.csv\", header=0)\n",
    "natureTypes = pd.read_csv(\"naturtyper.csv\", header=0)\n",
    "wordChecklist = natureTypes.copy()\n",
    "natureTypes[\"naturtyp\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>namn</th>\n",
       "      <th>riktigaNamn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ackspett</td>\n",
       "      <td>hackspett</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adfågel</td>\n",
       "      <td>åd(a)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aftonfalk</td>\n",
       "      <td>aftonfalk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aftonfågel</td>\n",
       "      <td>taltrast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aikamies</td>\n",
       "      <td>tofsmes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4145</th>\n",
       "      <td>örra</td>\n",
       "      <td>alfågel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4146</th>\n",
       "      <td>örr</td>\n",
       "      <td>se orre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4147</th>\n",
       "      <td>örre</td>\n",
       "      <td>se orre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4148</th>\n",
       "      <td>östkucku</td>\n",
       "      <td>se under gök</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4149</th>\n",
       "      <td>ötjeteta</td>\n",
       "      <td>drillsnäp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4150 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            namn   riktigaNamn\n",
       "0       ackspett     hackspett\n",
       "1        adfågel         åd(a)\n",
       "2      aftonfalk     aftonfalk\n",
       "3     aftonfågel      taltrast\n",
       "4       aikamies       tofsmes\n",
       "...          ...           ...\n",
       "4145        örra       alfågel\n",
       "4146         örr       se orre\n",
       "4147        örre       se orre\n",
       "4148    östkucku  se under gök\n",
       "4149    ötjeteta     drillsnäp\n",
       "\n",
       "[4150 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "birdsDia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addWords(word, onlyDeclension = True): \n",
    "    global wordChecklist\n",
    "    if onlyDeclension:\n",
    "        wordDec = getDeclension(word)[1:]\n",
    "        wordDecFrame = pd.DataFrame([wordDec[0],wordDec[1],wordDec[2]], columns=[\"naturtyp\"])\n",
    "    else:\n",
    "        wordDec = getDeclension(word)\n",
    "        wordDecFrame = pd.DataFrame([wordDec[0],wordDec[1],wordDec[2],wordDec[3]], columns=[\"naturtyp\"])\n",
    "    wordChecklist = pd.concat([wordChecklist,wordDecFrame])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in natureTypes[\"naturtyp\"].values:\n",
    "    addWords(x)\n",
    "\n",
    "for x in birds[\"namn\"].values:\n",
    "    addWords(x, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>naturtyp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sandbank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>estuarium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sandbotten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lerbotten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blottade ler- och sandbotten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doppingfåglarna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seglarfågel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seglarfågeln</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seglarfåglar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seglarfåglarna</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5540 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        naturtyp\n",
       "0                       sandbank\n",
       "1                      estuarium\n",
       "2                     sandbotten\n",
       "3                      lerbotten\n",
       "4   blottade ler- och sandbotten\n",
       "..                           ...\n",
       "3                doppingfåglarna\n",
       "0                    seglarfågel\n",
       "1                   seglarfågeln\n",
       "2                   seglarfåglar\n",
       "3                 seglarfåglarna\n",
       "\n",
       "[5540 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 20)\n",
    "wordChecklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tmpuser/code/Exjobb-main/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-07-01 14:40:41.651565: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModel,pipeline\n\u001b[1;32m      3\u001b[0m ner \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mner\u001b[39m\u001b[38;5;124m'\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKB/bert-base-swedish-cased-ner\u001b[39m\u001b[38;5;124m'\u001b[39m, tokenizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKB/bert-base-swedish-cased-ner\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m pos \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken-classification\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKBLab/bert-base-swedish-cased-pos\u001b[39m\u001b[38;5;124m\"\u001b[39m, tokenizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKBLab/bert-base-swedish-cased-pos\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1412\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m~/code/Exjobb-main/venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:1525\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1523\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1525\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1526\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1527\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/code/Exjobb-main/venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:1535\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1534\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1535\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1536\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1537\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1538\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1539\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1540\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.12/importlib/__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/Exjobb-main/venv/lib/python3.12/site-packages/transformers/pipelines/__init__.py:26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdynamic_module_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_class_from_dynamic_module\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedFeatureExtractor\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_processing_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseImageProcessor\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_auto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoConfig\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction_auto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FEATURE_EXTRACTOR_MAPPING, AutoFeatureExtractor\n",
      "File \u001b[0;32m~/code/Exjobb-main/venv/lib/python3.12/site-packages/transformers/image_processing_utils.py:28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdynamic_module_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m custom_object_save\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BatchFeature \u001b[38;5;28;01mas\u001b[39;00m BaseBatchFeature\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_transforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m center_crop, normalize, rescale\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChannelDimension\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     31\u001b[0m     IMAGE_PROCESSOR_NAME,\n\u001b[1;32m     32\u001b[0m     PushToHubMixin,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m     logging,\n\u001b[1;32m     41\u001b[0m )\n",
      "File \u001b[0;32m~/code/Exjobb-main/venv/lib/python3.12/site-packages/transformers/image_transforms.py:47\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_tf_available():\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_flax_available():\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mjnp\u001b[39;00m\n",
      "File \u001b[0;32m~/code/Exjobb-main/venv/lib/python3.12/site-packages/tensorflow/__init__.py:45\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[1;32m     43\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio\n",
      "File \u001b[0;32m~/code/Exjobb-main/venv/lib/python3.12/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dispatch\n",
      "File \u001b[0;32m~/code/Exjobb-main/venv/lib/python3.12/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.autograph namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mag_ctx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m control_status_ctx \u001b[38;5;66;03m# line: 34\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_convert \u001b[38;5;66;03m# line: 493\u001b[39;00m\n",
      "File \u001b[0;32m~/code/Exjobb-main/venv/lib/python3.12/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ag_logging\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[1;32m     25\u001b[0m stacks \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mlocal()\n",
      "File \u001b[0;32m~/code/Exjobb-main/venv/lib/python3.12/site-packages/tensorflow/python/autograph/utils/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext_managers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m control_dependency_on_returns\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m alias_tensors\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor_list\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dynamic_list_append\n",
      "File \u001b[0;32m~/code/Exjobb-main/venv/lib/python3.12/site-packages/tensorflow/python/autograph/utils/context_managers.py:19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Various context managers.\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcontextlib\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcontrol_dependency_on_returns\u001b[39m(return_value):\n",
      "File \u001b[0;32m~/code/Exjobb-main/venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:45\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_pb2\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# pywrap_tensorflow must be imported first to avoid protobuf issues.\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# (b/143110113)\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# pylint: disable=invalid-import-order,g-bad-import-order,unused-import\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tfe\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# pylint: enable=invalid-import-order,g-bad-import-order,unused-import\u001b[39;00m\n",
      "File \u001b[0;32m~/code/Exjobb-main/venv/lib/python3.12/site-packages/tensorflow/python/pywrap_tensorflow.py:34\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplatform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m self_check\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# TODO(mdan): Cleanup antipattern: import for side effects.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Perform pre-load sanity checks in order to produce a more actionable error.\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[43mself_check\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreload_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# pylint: disable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m   \u001b[38;5;66;03m# This import is expected to fail if there is an explicit shared object\u001b[39;00m\n\u001b[1;32m     40\u001b[0m   \u001b[38;5;66;03m# dependency (with_framework_lib=true), since we do not need RTLD_GLOBAL.\u001b[39;00m\n",
      "File \u001b[0;32m~/code/Exjobb-main/venv/lib/python3.12/site-packages/tensorflow/python/platform/self_check.py:63\u001b[0m, in \u001b[0;36mpreload_check\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     51\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find the DLL(s) \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m. TensorFlow requires that these DLLs \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     52\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbe installed in a directory that is named in your \u001b[39m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;124mPATH\u001b[39m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://support.microsoft.com/help/2977003/the-latest-supported-visual-c-downloads\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m           \u001b[38;5;241m%\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(missing))\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m   \u001b[38;5;66;03m# Load a library that performs CPU feature guard checking.  Doing this here\u001b[39;00m\n\u001b[1;32m     60\u001b[0m   \u001b[38;5;66;03m# as a preload check makes it more likely that we detect any CPU feature\u001b[39;00m\n\u001b[1;32m     61\u001b[0m   \u001b[38;5;66;03m# incompatibilities before we trigger them (which would typically result in\u001b[39;00m\n\u001b[1;32m     62\u001b[0m   \u001b[38;5;66;03m# SIGILL).\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplatform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_cpu_feature_guard\n\u001b[1;32m     64\u001b[0m   _pywrap_cpu_feature_guard\u001b[38;5;241m.\u001b[39mInfoAboutUnusedCPUFeatures()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel,pipeline\n",
    "\n",
    "ner = pipeline('ner', model='KB/bert-base-swedish-cased-ner', tokenizer='KB/bert-base-swedish-cased-ner')\n",
    "pos = pipeline(\"token-classification\", model=\"KBLab/bert-base-swedish-cased-pos\", tokenizer=\"KBLab/bert-base-swedish-cased-pos\")\n",
    "sentiment = pipeline(\"text-classification\", model=\"KBLab/robust-swedish-sentiment-multiclass\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVerbs(text):\n",
    "    posText = pos(text)\n",
    "    l = []\n",
    "    for token in posText:\n",
    "        try:\n",
    "            if token['word'].startswith('##'):\n",
    "                l[-1]['word'] += token['word'][2:]\n",
    "            else:\n",
    "                l += [ token ]\n",
    "        except:\n",
    "            print(f\"failed with {token}\")\n",
    "    return [x[\"word\"] for x in list(filter(lambda d: d['entity'] == \"VB\", l))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNamed(text):\n",
    "    interestingTags = [\"PRS\", \"LOC\", \"ORG\", \"OBJ\"]\n",
    "    posText = ner(text)\n",
    "    l = []\n",
    "    for token in posText:\n",
    "        try:\n",
    "            if token['word'].startswith('##'):\n",
    "                l[-1]['word'] += token['word'][2:]\n",
    "            else:\n",
    "                l += [ token ]\n",
    "        except:\n",
    "            print(f\"failed with {token}\")\n",
    "    return [x[\"word\"] for x in list(filter(lambda d: d['entity'] in interestingTags, l))]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>naturtyp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sandbank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>estuarium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sandbotten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lerbotten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blottade ler- och sandbotten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doppingfåglarna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seglarfågel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seglarfågeln</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seglarfåglar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seglarfåglarna</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5540 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        naturtyp\n",
       "0                       sandbank\n",
       "1                      estuarium\n",
       "2                     sandbotten\n",
       "3                      lerbotten\n",
       "4   blottade ler- och sandbotten\n",
       "..                           ...\n",
       "3                doppingfåglarna\n",
       "0                    seglarfågel\n",
       "1                   seglarfågeln\n",
       "2                   seglarfåglar\n",
       "3                 seglarfåglarna\n",
       "\n",
       "[5540 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordChecklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatDictDF(dict, pastDf):\n",
    "    return pastDf.combine_first(pd.DataFrame.from_dict(dict))\n",
    "#    return pd.concat([pastDf,pd.DataFrame.from_dict(dict)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_index = {}\n",
    "filtered_count_index = {}\n",
    "yearCounts = {}\n",
    "\n",
    "for y in years:\n",
    "    yearCounts.update({str(y):0})\n",
    "totalCount = 0\n",
    "\n",
    "\n",
    "\"\"\" def addToIndex(row):\n",
    "    tmp = 0\n",
    "    global master_index\n",
    "    global filtered_count_index\n",
    "    tokens = tokenize(row[\"content\"])\n",
    "    idx, wordCount = text_to_idx(tokens)\n",
    "    year = row[\"created\"][:4]\n",
    "    yearCounts[year] += wordCount\n",
    "    for word in idx.keys():\n",
    "        if word in master_index:\n",
    "            master_index[word][row[\"dark_id\"], year] = idx[word]\n",
    "        else:\n",
    "            master_index[word] = {(row[\"dark_id\"], year):idx[word]}\n",
    "        if word in wordChecklist[\"naturtyp\"].values:\n",
    "              filtered_entry = {word:{row[\"dark_id\"]:len(idx[word])}}\n",
    "              filtered_count_index = concatDictDF(filtered_entry,filtered_count_index)\n",
    "                     \"\"\"\n",
    "        \n",
    "def addToIndex(row, saveIndex):\n",
    "    tmp = 0\n",
    "    global master_index\n",
    "    global filtered_count_index\n",
    "    tokens = tokenize(row[\"content\"])\n",
    "    idx, wordCount = text_to_idx(tokens)\n",
    "    year = row[\"created\"][:4]\n",
    "    yearCounts[year] += wordCount\n",
    "    for word in idx.keys():\n",
    "        #if word in master_index:\n",
    "        #    master_index[word][row[\"dark_id\"], year] = idx[word]\n",
    "        #else:\n",
    "        #    master_index[word] = {(row[\"dark_id\"], year):idx[word]}\n",
    "        if saveIndex == 1:\n",
    "          if word in wordChecklist[\"naturtyp\"].values:\n",
    "#                filtered_entry = {word:{row[\"dark_id\"]:len(idx[word])}}\n",
    "                \n",
    "                if word in filtered_count_index:               \n",
    "                  filtered_count_index[word][row[\"dark_id\"]] = len(idx[word])\n",
    "                else:\n",
    "                  #master_index[word] = {(row[\"dark_id\"], year):idx[word]}\n",
    "                  filtered_count_index[word] = {row[\"dark_id\"]:len(idx[word])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_count_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "addToIndex() missing 1 required positional argument: 'saveIndex'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_content\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maddToIndex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/Exjobb-main/venv/lib/python3.12/site-packages/pandas/core/frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10373\u001b[0m )\n\u001b[0;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/code/Exjobb-main/venv/lib/python3.12/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/Exjobb-main/venv/lib/python3.12/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m~/code/Exjobb-main/venv/lib/python3.12/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_content[:\u001b[38;5;241m10\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[43maddToIndex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: addToIndex() missing 1 required positional argument: 'saveIndex'"
     ]
    }
   ],
   "source": [
    "df_content[:10].apply(lambda row: addToIndex(row,1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>albatross</th>\n",
       "      <th>alfågel</th>\n",
       "      <th>alfåglarna</th>\n",
       "      <th>and</th>\n",
       "      <th>barrskog</th>\n",
       "      <th>barrskogar</th>\n",
       "      <th>betesmark</th>\n",
       "      <th>blåmes</th>\n",
       "      <th>bofink</th>\n",
       "      <th>bofinkar</th>\n",
       "      <th>...</th>\n",
       "      <th>älven</th>\n",
       "      <th>änder</th>\n",
       "      <th>äng</th>\n",
       "      <th>ängar</th>\n",
       "      <th>ängarna</th>\n",
       "      <th>ängen</th>\n",
       "      <th>ö</th>\n",
       "      <th>öar</th>\n",
       "      <th>öarna</th>\n",
       "      <th>ön</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dark-102395</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dark-102406</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dark-102409</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dark-102405</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dark-102404</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dark-102398</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dark-102407</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dark-102408</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dark-102412</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dark-102396</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 156 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             albatross  alfågel  alfåglarna   and  barrskog  barrskogar  \\\n",
       "dark-102395        2.0      NaN         NaN   5.0       NaN         NaN   \n",
       "dark-102406        NaN      NaN         NaN   5.0       NaN         NaN   \n",
       "dark-102409        NaN      NaN         NaN   8.0       1.0         NaN   \n",
       "dark-102405        NaN      NaN         NaN   5.0       2.0         NaN   \n",
       "dark-102404        NaN      NaN         NaN   8.0       2.0         NaN   \n",
       "dark-102398        NaN      NaN         NaN   2.0       1.0         NaN   \n",
       "dark-102407        NaN      NaN         NaN   8.0       3.0         NaN   \n",
       "dark-102408        NaN      NaN         NaN  13.0       2.0         1.0   \n",
       "dark-102412        NaN      1.0         2.0   2.0       NaN         1.0   \n",
       "dark-102396        NaN      NaN         NaN   2.0       NaN         NaN   \n",
       "\n",
       "             betesmark  blåmes  bofink  bofinkar  ...  älven  änder  äng  \\\n",
       "dark-102395        NaN     NaN     NaN       NaN  ...    NaN    NaN  3.0   \n",
       "dark-102406        1.0     NaN     NaN       NaN  ...    NaN    NaN  NaN   \n",
       "dark-102409        NaN     NaN     NaN       NaN  ...    NaN    NaN  1.0   \n",
       "dark-102405        NaN     1.0     1.0       1.0  ...    4.0    3.0  NaN   \n",
       "dark-102404        NaN     NaN     NaN       NaN  ...    NaN    NaN  1.0   \n",
       "dark-102398        NaN     NaN     NaN       NaN  ...    NaN    NaN  1.0   \n",
       "dark-102407        NaN     NaN     NaN       NaN  ...    NaN    NaN  NaN   \n",
       "dark-102408        NaN     NaN     NaN       NaN  ...    NaN    NaN  1.0   \n",
       "dark-102412        NaN     NaN     NaN       NaN  ...    NaN    NaN  NaN   \n",
       "dark-102396        NaN     NaN     NaN       NaN  ...    1.0    NaN  1.0   \n",
       "\n",
       "             ängar  ängarna  ängen     ö  öar  öarna    ön  \n",
       "dark-102395    NaN      1.0    NaN  35.0  NaN    1.0   1.0  \n",
       "dark-102406    1.0      1.0    NaN  39.0  NaN    NaN   1.0  \n",
       "dark-102409    NaN      NaN    NaN  36.0  2.0    NaN   5.0  \n",
       "dark-102405    1.0      2.0    NaN  31.0  2.0    2.0  21.0  \n",
       "dark-102404    NaN      NaN    NaN  34.0  2.0    NaN   2.0  \n",
       "dark-102398    NaN      NaN    1.0  42.0  NaN    1.0   3.0  \n",
       "dark-102407    NaN      NaN    NaN  35.0  1.0    NaN   NaN  \n",
       "dark-102408    1.0      2.0    1.0  47.0  1.0    2.0   4.0  \n",
       "dark-102412    NaN      NaN    1.0  44.0  NaN    3.0   2.0  \n",
       "dark-102396    NaN      1.0    NaN  33.0  NaN    1.0   1.0  \n",
       "\n",
       "[10 rows x 156 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_count_index.sort_values(by=\"uggla\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74555"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(master_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices(lst, element):\n",
    "    result = []\n",
    "    offset = -1\n",
    "    while True:\n",
    "        try:\n",
    "            offset = lst.index(element, offset+1)\n",
    "        except ValueError:\n",
    "            return result\n",
    "        result.append(offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "def getDocs(word):\n",
    "    global docs\n",
    "    master_index_bird = master_index[word]\n",
    "    for issue, year in master_index_bird:\n",
    "        res = df_content.loc[df_content[\"dark_id\"] == issue]\n",
    "        res = res[\"content\"].values\n",
    "        textBlock = res[0].lower().replace(\",\", \"\")\n",
    "        n = 10\n",
    "        idxs = indices(textBlock, word)\n",
    "        for id in idxs:\n",
    "            lhs, bird, rhs = textBlock[id-50:id+50].partition(word)\n",
    "            sentimentWindow = \" \".join(lhs.split()[-n:] + [bird] + rhs.split()[:n])\n",
    "            docs.append(sentimentWindow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, b in filtered_count_index.items():\n",
    "    getDocs(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89345"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 17:04:09,365 - BERTopic - Embedding - Transforming documents to embeddings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2793/2793 [01:18<00:00, 35.42it/s]\n",
      "2024-07-02 17:05:31,775 - BERTopic - Embedding - Completed ✓\n",
      "2024-07-02 17:05:31,778 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2024-07-02 17:06:55,860 - BERTopic - Dimensionality - Completed ✓\n",
      "2024-07-02 17:06:55,864 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-07-02 17:07:04,414 - BERTopic - Cluster - Completed ✓\n",
      "2024-07-02 17:07:04,438 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2024-07-02 17:07:06,766 - BERTopic - Representation - Completed ✓\n"
     ]
    }
   ],
   "source": [
    "from bertopic import BERTopic\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "\n",
    "ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)\n",
    "\n",
    "\n",
    "topic_model = BERTopic(embedding_model='KBLab/sentence-bert-swedish-cased', verbose=True, ctfidf_model=ctfidf_model)\n",
    "topics, probs = topic_model.fit_transform(docs)\n",
    "\n",
    "embedding_model = 'KBLab/sentence-bert-swedish-cased'\n",
    "topic_model.save(\"ownData/\", serialization=\"safetensors\", save_ctfidf=True, save_embedding_model=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CountVectorizer' object has no attribute 'get_feature_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m topic_term_matrix \u001b[38;5;241m=\u001b[39m topic_model\u001b[38;5;241m.\u001b[39mc_tf_idf_\n\u001b[0;32m----> 2\u001b[0m words \u001b[38;5;241m=\u001b[39m \u001b[43mtopic_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvectorizer_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_feature_names\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CountVectorizer' object has no attribute 'get_feature_names'"
     ]
    }
   ],
   "source": [
    "topic_term_matrix = topic_model.c_tf_idf_\n",
    "words = topic_model.vectorizer_model.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('flugsnappare', 0.24957560984977473),\n",
       " ('hussvala', 0.24634214727174225),\n",
       " ('ladusvala', 0.24634214727174225),\n",
       " ('grönsiska', 0.24634214727174225),\n",
       " ('fåglar', 0.24511798954045613),\n",
       " ('blåmes', 0.2429227390481649),\n",
       " ('fröätande', 0.23929740580467726),\n",
       " ('trädkrypare', 0.2354426768370055),\n",
       " ('svartmes', 0.2354426768370055),\n",
       " ('grönfink', 0.23133070496419383)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_topics, similarity = topic_model.find_topics(\"fågel\", top_n=5)\n",
    "topic_model.get_topic(similar_topics[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              fåggel   ö\n",
      "dark-1021238    20.0  20\n",
      "dark-102238     50.0  50\n"
     ]
    }
   ],
   "source": [
    "tmpdf = pd.DataFrame()\n",
    "tmp12 = pd.DataFrame.from_dict({\"ö\":{\"dark-102238\":50}})\n",
    "tmp13 = pd.DataFrame.from_dict({\"ö\":{\"dark-1021238\":20}})\n",
    "tmp15 = pd.DataFrame.from_dict({\"fåggel\":{\"dark-102238\":50}})\n",
    "tmp14 = pd.DataFrame.from_dict({\"fåggel\":{\"dark-1021238\":20}})\n",
    "tmpdf = concatDictDF(tmp12,tmpdf)\n",
    "tmpdf = concatDictDF(tmp13,tmpdf)\n",
    "tmpdf = concatDictDF(tmp15,tmpdf)\n",
    "tmpdf = concatDictDF(tmp14,tmpdf)\n",
    "print(tmpdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_count_index[\"uggla\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counter(word):\n",
    "  master_index_bird = master_index[word]\n",
    "  count = {}\n",
    "\n",
    "  for y in years:\n",
    "    count.update({str(y): {\"freq\":0, \"count\":0, \"prob\":0}})\n",
    "  for a,b in master_index_bird:\n",
    "    if b in count:\n",
    "      count[b][\"count\"] += 1\n",
    "    else:\n",
    "      count[b][\"count\"] = 1\n",
    "  for y in years:\n",
    "    try:\n",
    "      count[str(y)][\"freq\"] = count[str(y)][\"count\"]/yearCounts[str(y)]*100000\n",
    "      count[str(y)][\"prob\"] = count[str(y)][\"count\"]/yearCounts[str(y)]\n",
    "    except:\n",
    "      count[str(y)][\"freq\"] = 0.0\n",
    "  return count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWordCooccurenceAndSentiment(word):\n",
    "  yearsString = [str(y) for y in years]\n",
    "  master_index_bird = master_index[word]\n",
    "  sentimentByYear = {}\n",
    "  global df_numpy\n",
    "  cooccurence = {}\n",
    "  for y in years:\n",
    "    cooccurence.update({str(y):{}})\n",
    "    sentimentByYear.update({str(y):[]})\n",
    "  for issue, year in master_index_bird:\n",
    "    rows, cols = np.where(df_numpy == issue)\n",
    "    textBlock = df_numpy[rows][0][0].lower().replace(\",\", \"\")\n",
    "    n = 5\n",
    "    lhs, bird, rhs = textBlock.partition(word)\n",
    "    window = lhs.split()[-n:] + rhs.split()[:n]\n",
    "    sentimentWindow = \" \".join(lhs.split()[-n:] + [bird] + rhs.split()[:n])\n",
    "    textSentiment = sentiment(sentimentWindow)[0][\"label\"]\n",
    "    sentimentByYear[year].append(textSentiment)\n",
    "    birdWords = list(filter(None, window))\n",
    "    #verbs = getVerbs(\" \".join(birdWords))\n",
    "    #named = getNamed(tmp)\n",
    "    #natureWords = [k for k in birdWords if k in wordChecklistList]\n",
    "    #interestingWords = verbs + natureWords\n",
    "    #print(f\"all: {birdWords}\")\n",
    "    #print(f\"verbs {verbs}\")\n",
    "    #print(f\"nature: {natureWords}\")\n",
    "    for bWord in birdWords:\n",
    "      if bWord == word or bWord in yearsString:\n",
    "        continue\n",
    "      if bWord in cooccurence[year]:\n",
    "        cooccurence[year][bWord] += 1\n",
    "      else:\n",
    "        cooccurence[year][bWord] = 1\n",
    "      #print(f\"checking {bWord}\")    \n",
    "  return cooccurence, sentimentByYear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortCooccurence(a):\n",
    "  return sorted(a.items(), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeCounts(c1, c2):\n",
    "  tmp = {}\n",
    "  for y in years:\n",
    "    tmp[str(y)] = {\"freq\": c1[str(y)][\"freq\"] + c2[str(y)][\"freq\"], \"count\": c1[str(y)][\"count\"] + c2[str(y)][\"count\"], \"prob\": c1[str(y)][\"prob\"] + c2[str(y)][\"prob\"]}\n",
    "  return tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeCoocs(c1, c2):\n",
    "  tmp = {}\n",
    "  for y in years:\n",
    "    tmp[str(y)] = {k: (c1[str(y)].get(k, 0) + c2[str(y)].get(k, 0)) for k in set(c1[str(y)]) | set(c2[str(y)])}\n",
    "  return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeSentiment(s1,s2):\n",
    "    tmp = {}\n",
    "    for y in years:\n",
    "        tmp1 = s1[str(y)]\n",
    "        tmp2 = s2[str(y)]\n",
    "        tmp[str(y)] = tmp1+tmp2\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_906853/3438062497.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if bird[0] in frequency:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "frequency = {}\n",
    "cooccurenceMatrix = {}\n",
    "\n",
    "for i, bird in birds.iterrows():\n",
    "  specificbird = bird[\"namn\"]\n",
    "  birds_dec = getDeclension(specificbird)\n",
    "  for bd in birds_dec:\n",
    "    try:\n",
    "      bc = counter(bd)\n",
    "      if bird[0] in frequency:\n",
    "        freq = frequency[specificbird]\n",
    "      else:\n",
    "        freq = {}\n",
    "        for y in years:\n",
    "          freq.update({str(y):{\"freq\":0, \"count\":0, \"prob\":0}})\n",
    "      frequency[specificbird] = mergeCounts(bc, freq)\n",
    "    except:\n",
    "      \"lmao\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency.keys()\n",
    "dataFreq = {}\n",
    "dataCount = {}\n",
    "\n",
    "for b in frequency.keys():\n",
    "    dataFreq.update({b: [frequency[b][x][\"freq\"] for x in frequency[b]]})\n",
    "    dataCount.update({b: [frequency[b][x][\"count\"] for x in frequency[b]]})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFreq = pd.DataFrame.from_dict(dataFreq, orient=\"index\", columns=years)\n",
    "dfCount = pd.DataFrame.from_dict(dataCount, orient=\"index\", columns=years)\n",
    "dfFreq.to_feather(f\"/data/birdNewsData/birdFreq/dfFreq_{years[0]}s.feather\")\n",
    "dfCount.to_feather(f\"/data/birdNewsData/birdFreq/dfCount_{years[0]}s.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(yearCounts, orient=\"index\", columns=[\"word count\"]).to_feather(f\"/data/birdNewsData/birdFreq/dfYearCount_{years[0]}s.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1930</th>\n",
       "      <th>1931</th>\n",
       "      <th>1932</th>\n",
       "      <th>1933</th>\n",
       "      <th>1934</th>\n",
       "      <th>1935</th>\n",
       "      <th>1936</th>\n",
       "      <th>1937</th>\n",
       "      <th>1938</th>\n",
       "      <th>1939</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fågel</th>\n",
       "      <td>0.680119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.331702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.446801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.181226</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>andfågel</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.291463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gås</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.582926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.787204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svan</th>\n",
       "      <td>0.680119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.874388</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.446801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.393742</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>2.040358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.040239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.893602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.393742</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gråsparv</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.291463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ärla</th>\n",
       "      <td>0.680119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>domherre</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.446801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kanariefågel</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.893602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.393742</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kardinal</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.291463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.446801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  1930  1931      1932  1933  1934  1935      1936  1937  \\\n",
       "fågel         0.680119   0.0  2.331702   0.0   0.0   0.0  1.446801   0.0   \n",
       "andfågel      0.000000   0.0  0.291463   0.0   0.0   0.0  0.000000   0.0   \n",
       "gås           0.000000   0.0  0.582926   0.0   0.0   0.0  5.787204   0.0   \n",
       "svan          0.680119   0.0  0.874388   0.0   0.0   0.0  1.446801   0.0   \n",
       "and           2.040358   0.0  2.040239   0.0   0.0   0.0  2.893602   0.0   \n",
       "...                ...   ...       ...   ...   ...   ...       ...   ...   \n",
       "gråsparv      0.000000   0.0  0.291463   0.0   0.0   0.0  0.000000   0.0   \n",
       "ärla          0.680119   0.0  0.000000   0.0   0.0   0.0  0.000000   0.0   \n",
       "domherre      0.000000   0.0  0.000000   0.0   0.0   0.0  1.446801   0.0   \n",
       "kanariefågel  0.000000   0.0  0.000000   0.0   0.0   0.0  2.893602   0.0   \n",
       "kardinal      0.000000   0.0  0.291463   0.0   0.0   0.0  1.446801   0.0   \n",
       "\n",
       "                   1938  1939  \n",
       "fågel         10.181226   0.0  \n",
       "andfågel       0.000000   0.0  \n",
       "gås            0.000000   0.0  \n",
       "svan           3.393742   0.0  \n",
       "and            3.393742   0.0  \n",
       "...                 ...   ...  \n",
       "gråsparv       0.000000   0.0  \n",
       "ärla           0.000000   0.0  \n",
       "domherre       0.000000   0.0  \n",
       "kanariefågel   3.393742   0.0  \n",
       "kardinal       0.000000   0.0  \n",
       "\n",
       "[44 rows x 10 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_feather(f\"/data/birdNewsData/birdFreq/dfFreq_{years[0]}s.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fågel\n",
      "['fågel', 'fågeln', 'fåglar', 'fåglarna']\n",
      "fågel start\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[146], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bd \u001b[38;5;129;01min\u001b[39;00m birds_dec:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbd\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m     coWord, senWord \u001b[38;5;241m=\u001b[39m \u001b[43mgetWordCooccurenceAndSentiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m specificbird \u001b[38;5;129;01min\u001b[39;00m cooccurenceMatrix:\n\u001b[1;32m     13\u001b[0m         co \u001b[38;5;241m=\u001b[39m cooccurenceMatrix[specificbird]\n",
      "Cell \u001b[0;32mIn[136], line 11\u001b[0m, in \u001b[0;36mgetWordCooccurenceAndSentiment\u001b[0;34m(word)\u001b[0m\n\u001b[1;32m      9\u001b[0m   sentimentByYear\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;28mstr\u001b[39m(y):[]})\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m issue, year \u001b[38;5;129;01min\u001b[39;00m master_index_bird:\n\u001b[0;32m---> 11\u001b[0m   rows, cols \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(\u001b[43mdf_numpy\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43missue\u001b[49m)\n\u001b[1;32m     12\u001b[0m   textBlock \u001b[38;5;241m=\u001b[39m df_numpy[rows][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m   n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "\n",
    "for i, bird in birds.iterrows():\n",
    "    specificbird = bird[\"namn\"]\n",
    "    print(specificbird)\n",
    "    birds_dec = getDeclension(specificbird)\n",
    "    print(birds_dec)\n",
    "\n",
    "    cooccurenceMatrix = {}\n",
    "    sentimentMatrix = {}\n",
    "    for bd in birds_dec:\n",
    "        print(f\"{bd} start\")\n",
    "        coWord, senWord = getWordCooccurenceAndSentiment(bd)\n",
    "        if specificbird in cooccurenceMatrix:\n",
    "            co = cooccurenceMatrix[specificbird]\n",
    "            cooccurenceMatrix[specificbird] = mergeCoocs(co, coWord)\n",
    "        else:\n",
    "            cooccurenceMatrix[specificbird] = coWord\n",
    "\n",
    "        if specificbird in sentimentMatrix:\n",
    "            se = sentimentMatrix[specificbird]\n",
    "            sentimentMatrix[specificbird] = mergeSentiment(se, senWord)\n",
    "        else:\n",
    "            sentimentMatrix[specificbird] = senWord\n",
    "        print(f\"{bd} done\")\n",
    "    \n",
    "    pd.DataFrame.from_dict(cooccurenceMatrix[specificbird]).to_feather(f\"/data/birdNewsData/birdFreq/df_co_{years[0]}s_{specificbird}.feather\")\n",
    "    specificSentiment = sentimentMatrix[specificbird]\n",
    "    tmp = {}\n",
    "    for y in years:\n",
    "        yearlySentiment = specificSentiment[str(y)]\n",
    "        countNegative = yearlySentiment.count(\"NEGATIVE\")\n",
    "        countPositive = yearlySentiment.count(\"POSITIVE\")\n",
    "        CountNeutral = yearlySentiment.count(\"NEUTRAL\")\n",
    "        tmp[y] = {\"Positive\": countPositive,\"Neutral\":CountNeutral, \"Negative\" : countNegative}\n",
    "    pd.DataFrame.from_dict(tmp).to_feather(f\"/data/birdNewsData/birdFreq/df_sen_{years[0]}s_{specificbird}.feather\")\n",
    "    #break\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "def getCoWordsCount(bird):\n",
    "    tmp = 0\n",
    "    specificMatrix = cooccurenceMatrix[bird]\n",
    "    SavedCounts = {}\n",
    "    for y in years:\n",
    "        for x in specificMatrix[str(y)].keys():\n",
    "            if not (x in SavedCounts):\n",
    "                try:\n",
    "                    tmp1 = [counter(x)[str(y)][\"count\"] for y in years]\n",
    "                    SavedCounts[x] = tmp1\n",
    "                except:\n",
    "                    \"not in index...\"\n",
    "    return SavedCounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "tmpFa = getCoWordsCount(\"fågel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "tmpFa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df_coCount = pd.DataFrame.from_dict(tmpFa, orient=\"index\", columns=years)\n",
    "df_coCount.to_feather(f\"/data/birdNewsData/birdFreq/df_coWord_{years[0]}s_fågel.feather\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "pd.read_feather(f\"/data/birdNewsData/birdFreq/df_coWord_{years[0]}s_fågel.feather\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def getTScore(bird, year):\n",
    "  ts = {}\n",
    "  skipwords = [\"och\", \"i\", \"en\", \"som\", \"att\", \"kan\", \"den\", \"ett\"]\n",
    "  for word, count_co in cooccurenceMatrix[bird][year].items():\n",
    "    if word in skipwords:\n",
    "      continue\n",
    "    try:\n",
    "      count_word = counter(word)[year][\"count\"]\n",
    "      prob_word = count_word/yearCounts[year] *100000\n",
    "      prob_bird = frequency[bird][year][\"freq\"]\n",
    "      prob_both = count_co/yearCounts[year] * 100000\n",
    "\n",
    "      ts[word] = ((\n",
    "        prob_both -\n",
    "        prob_bird *\n",
    "        prob_word /\n",
    "        yearCounts[year] /\n",
    "        math.sqrt(prob_both)\n",
    "      ))\n",
    "    except:\n",
    "      \"lmao\"\n",
    "  return sorted(ts.items(), key=lambda x:x[1], reverse=True)[:10]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def getPMIs(bird, year):\n",
    "  tmp = []\n",
    "  count_bird = frequency[bird][year][\"count\"]\n",
    "  #print(\"count b\\t\", count_bird)\n",
    "  prob_bird = frequency[bird][year][\"prob\"]\n",
    "  #print(\"prob b\\t\", prob_bird)\n",
    "  i = 0\n",
    "  for word, count_co in cooccurenceMatrix[\"Domherre\"][year].items():\n",
    "    try:\n",
    "      print(word)\n",
    "      i+=1\n",
    "      if i > 5:\n",
    "        break; \n",
    "      count_word = counter(word)[year][\"count\"]\n",
    "      #print(\"count w\\t\", count_word)\n",
    "      prob_word = count_word/yearCounts[year]\n",
    "      #print(\"prob w\\t\", prob_word)\n",
    "      #print(\"count co w\\t\", count_co)\n",
    "      prob = count_co/yearCounts[year]\n",
    "      #print(\"total prob\\t\", prob)\n",
    "      pmi = max(math.log(prob/(prob_bird*prob_word)),0)\n",
    "      #print(\"pmi\\t\", pmi)\n",
    "      tmp.append((word, pmi))\n",
    "      #print()\n",
    "    except:\n",
    "      \"oof\"\n",
    "  return sorted(tmp, key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "tmp = 0\n",
    "\n",
    "for bird, freq in frequency.items():\n",
    "  tmp +=1\n",
    "  onlyFreqs = {}\n",
    "  avg = 0\n",
    "  for f in freq:\n",
    "    onlyFreqs.update({str(f): freq[f][\"freq\"]})\n",
    "    avg += freq[f][\"freq\"]/10\n",
    "  if avg > 1:\n",
    "    plt.plot(onlyFreqs.keys(), onlyFreqs.values(), label=bird)\n",
    "\n",
    "\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
